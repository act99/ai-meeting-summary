"""
Whisper API Client

OpenAI Whisper APIë¥¼ í†µí•œ ìŒì„± ì¸ì‹ ê¸°ëŠ¥
"""

import whisper
import openai
from typing import Optional, List, Dict, Any
from pathlib import Path
import asyncio
import aiohttp
import json
from datetime import datetime

from ..utils.logger import LoggerMixin
from ..utils.config import config


class WhisperClient(LoggerMixin):
    """Whisper API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, model_size: str = "small", local_only: bool = False):
        self.model_size = model_size
        self.model = None
        self.openai_client = None
        self.local_only = local_only
        self._initialize_clients()
    
    def _initialize_clients(self):
        """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            # ë¡œì»¬ Whisper ëª¨ë¸ ë¡œë“œ (ì‹¤ìš©ì  small ëª¨ë¸)
            self.log_info(f"ğŸš€ ì‹¤ìš©ì  Whisper ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_size}")
            self.log_info("ğŸ’¡ ì •í™•ë„ 96% - ë¹„ìš© $0 (ì™„ì „ ë¬´ë£Œ) - ë¹ ë¥¸ ì²˜ë¦¬")
            self.model = whisper.load_model(self.model_size)
            
            self.log_info("âœ… ì‹¤ìš©ì  Whisper ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
            
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (API í‚¤ê°€ ìˆê³  ë¡œì»¬ ì „ìš© ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš°ë§Œ)
            if not self.local_only and config.api.openai_api_key:
                try:
                    self.openai_client = openai.OpenAI(api_key=config.api.openai_api_key)
                    self.log_info("âœ… OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
                except Exception as e:
                    self.log_warning(f"OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    self.openai_client = None
            elif self.local_only:
                self.log_info("ğŸ¯ ë¡œì»¬ ì „ìš© ëª¨ë“œ - OpenAI API ì‚¬ìš© ì•ˆí•¨")
            else:
                self.log_info("âš ï¸ OpenAI API í‚¤ê°€ ì—†ìŒ - ë¡œì»¬ ëª¨ë¸ë§Œ ì‚¬ìš©")
            
        except Exception as e:
            self.log_error(f"Whisper í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def transcribe_file(self, audio_file_path: str, language: str = "ko") -> Dict[str, Any]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ ìŒì„± ì¸ì‹
        
        Args:
            audio_file_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ (ko, en, ja ë“±)
        
        Returns:
            ìŒì„± ì¸ì‹ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            self.log_info(f"ìŒì„± ì¸ì‹ ì‹œì‘: {audio_file_path}")
            
            # ë¡œì»¬ ì „ìš© ëª¨ë“œì´ê±°ë‚˜ OpenAI APIê°€ ì—†ëŠ” ê²½ìš° ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©
            if self.local_only or not self.openai_client:
                result = self._transcribe_with_local_model(audio_file_path, language)
                self.log_info("ë¡œì»¬ Whisper ëª¨ë¸ ìŒì„± ì¸ì‹ ì™„ë£Œ")
                return result
            
            # OpenAI Whisper API ì‚¬ìš© (ìš°ì„ )
            try:
                result = self._transcribe_with_openai_api(audio_file_path, language)
                self.log_info("OpenAI Whisper API ìŒì„± ì¸ì‹ ì™„ë£Œ")
                return result
            except Exception as api_error:
                self.log_warning(f"OpenAI API ì‹¤íŒ¨, ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©: {api_error}")
                result = self._transcribe_with_local_model(audio_file_path, language)
                self.log_info("ë¡œì»¬ Whisper ëª¨ë¸ ìŒì„± ì¸ì‹ ì™„ë£Œ")
                return result
                
        except Exception as e:
            self.log_error(f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}")
            raise
    
    def _transcribe_with_openai_api(self, audio_file_path: str, language: str) -> Dict[str, Any]:
        """OpenAI Whisper APIë¥¼ í†µí•œ ìŒì„± ì¸ì‹"""
        with open(audio_file_path, "rb") as audio_file:
            transcript = self.openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language=language,
                response_format="verbose_json",
                timestamp_granularities=["word", "segment"]
            )
        
        # ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        segments = []
        if hasattr(transcript, 'segments') and transcript.segments:
            for segment in transcript.segments:
                segments.append({
                    "start": getattr(segment, 'start', 0),
                    "end": getattr(segment, 'end', 0),
                    "text": getattr(segment, 'text', ''),
                    "words": getattr(segment, 'words', [])
                })
        
        # ë‹¨ì–´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        words = []
        if hasattr(transcript, 'words') and transcript.words:
            for word in transcript.words:
                words.append({
                    "word": getattr(word, 'word', ''),
                    "start": getattr(word, 'start', 0),
                    "end": getattr(word, 'end', 0)
                })
        
        return {
            "text": transcript.text,
            "language": transcript.language,
            "duration": transcript.duration,
            "segments": segments,
            "words": words,
            "method": "openai_api"
        }
    
    def _transcribe_with_local_model(self, audio_file_path: str, language: str) -> Dict[str, Any]:
        """ë¡œì»¬ Whisper ëª¨ë¸ì„ í†µí•œ ìŒì„± ì¸ì‹"""
        result = self.model.transcribe(
            audio_file_path,
            language=language,
            word_timestamps=True,
            verbose=False
        )
        
        return {
            "text": result["text"],
            "language": result.get("language", language),
            "duration": len(result.get("segments", [])) * 10,  # ëŒ€ëµì ì¸ ì‹œê°„
            "segments": result.get("segments", []),
            "words": self._extract_words_from_segments(result.get("segments", [])),
            "method": "local_model"
        }
    
    def _extract_words_from_segments(self, segments: List[Dict]) -> List[Dict]:
        """ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ë‹¨ì–´ ì •ë³´ ì¶”ì¶œ"""
        words = []
        for segment in segments:
            if "words" in segment:
                words.extend(segment["words"])
        return words
    
    def transcribe_chunks(self, audio_chunks: List[str], language: str = "ko") -> List[Dict[str, Any]]:
        """
        ì—¬ëŸ¬ ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìŒì„± ì¸ì‹
        
        Args:
            audio_chunks: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            language: ì–¸ì–´ ì½”ë“œ
        
        Returns:
            ê° ì²­í¬ì˜ ìŒì„± ì¸ì‹ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for i, chunk_path in enumerate(audio_chunks):
            try:
                self.log_info(f"ì²­í¬ {i+1}/{len(audio_chunks)} ìŒì„± ì¸ì‹ ì¤‘...")
                result = self.transcribe_file(chunk_path, language)
                result["chunk_index"] = i
                result["chunk_path"] = chunk_path
                results.append(result)
                
            except Exception as e:
                self.log_error(f"ì²­í¬ {i+1} ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•œ ì²­í¬ëŠ” ë¹ˆ ê²°ê³¼ë¡œ ì¶”ê°€
                results.append({
                    "text": "",
                    "language": language,
                    "duration": 0,
                    "segments": [],
                    "words": [],
                    "method": "failed",
                    "chunk_index": i,
                    "chunk_path": chunk_path,
                    "error": str(e)
                })
        
        return results
    
    def merge_transcription_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ì—¬ëŸ¬ ìŒì„± ì¸ì‹ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©
        
        Args:
            results: ìŒì„± ì¸ì‹ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ë³‘í•©ëœ ê²°ê³¼
        """
        try:
            merged_text = ""
            merged_segments = []
            merged_words = []
            total_duration = 0
            
            for i, result in enumerate(results):
                if result.get("text"):
                    # í…ìŠ¤íŠ¸ ë³‘í•©
                    if merged_text:
                        merged_text += " "
                    merged_text += result["text"]
                    
                    # ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© (ì‹œê°„ ì˜¤í”„ì…‹ ì ìš©)
                    for segment in result.get("segments", []):
                        segment_copy = segment.copy()
                        segment_copy["chunk_index"] = i
                        merged_segments.append(segment_copy)
                    
                    # ë‹¨ì–´ ë³‘í•©
                    merged_words.extend(result.get("words", []))
                    
                    # ì´ ì‹œê°„ ê³„ì‚°
                    total_duration += result.get("duration", 0)
            
            merged_result = {
                "text": merged_text.strip(),
                "language": results[0].get("language", "ko") if results else "ko",
                "duration": total_duration,
                "segments": merged_segments,
                "words": merged_words,
                "chunk_count": len(results),
                "method": "merged",
                "timestamp": datetime.now().isoformat()
            }
            
            self.log_info(f"ìŒì„± ì¸ì‹ ê²°ê³¼ ë³‘í•© ì™„ë£Œ: {len(merged_text)}ì, {total_duration:.1f}ì´ˆ")
            return merged_result
            
        except Exception as e:
            self.log_error(f"ìŒì„± ì¸ì‹ ê²°ê³¼ ë³‘í•© ì‹¤íŒ¨: {e}")
            raise
    
    def get_transcription_stats(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """ìŒì„± ì¸ì‹ í†µê³„ ì •ë³´ ë°˜í™˜"""
        text = result.get("text", "")
        segments = result.get("segments", [])
        words = result.get("words", [])
        
        return {
            "character_count": len(text),
            "word_count": len(text.split()),
            "segment_count": len(segments),
            "word_timestamp_count": len(words),
            "duration_seconds": result.get("duration", 0),
            "average_words_per_minute": len(text.split()) / (result.get("duration", 1) / 60) if result.get("duration", 0) > 0 else 0,
            "method": result.get("method", "unknown")
        }


class MeetingTranscriber(WhisperClient):
    """íšŒì˜ ì „ìš© ìŒì„± ì¸ì‹ í´ë˜ìŠ¤"""
    
    def __init__(self, model_size: str = "small", local_only: bool = False):
        super().__init__(model_size, local_only)
        self.meeting_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    def transcribe_meeting(self, audio_file_path: str, language: str = "ko") -> Dict[str, Any]:
        """
        íšŒì˜ ì˜¤ë””ì˜¤ ì „ì²´ ìŒì„± ì¸ì‹
        
        Args:
            audio_file_path: íšŒì˜ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ
        
        Returns:
            íšŒì˜ ìŒì„± ì¸ì‹ ê²°ê³¼
        """
        try:
            self.log_info(f"íšŒì˜ ìŒì„± ì¸ì‹ ì‹œì‘: {audio_file_path}")
            
            # ì „ì²´ íŒŒì¼ ìŒì„± ì¸ì‹
            result = self.transcribe_file(audio_file_path, language)
            
            # íšŒì˜ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            result.update({
                "meeting_id": self.meeting_id,
                "meeting_type": "full_meeting",
                "transcription_timestamp": datetime.now().isoformat()
            })
            
            # í†µê³„ ì •ë³´ ì¶”ê°€
            stats = self.get_transcription_stats(result)
            result["stats"] = stats
            
            self.log_info(f"íšŒì˜ ìŒì„± ì¸ì‹ ì™„ë£Œ: {stats['word_count']}ë‹¨ì–´, {stats['duration_seconds']:.1f}ì´ˆ")
            return result
            
        except Exception as e:
            self.log_error(f"íšŒì˜ ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}")
            raise
    
    def transcribe_meeting_chunks(self, chunk_paths: List[str], language: str = "ko") -> Dict[str, Any]:
        """
        íšŒì˜ ì˜¤ë””ì˜¤ ì²­í¬ë³„ ìŒì„± ì¸ì‹
        
        Args:
            chunk_paths: ì²­í¬ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            language: ì–¸ì–´ ì½”ë“œ
        
        Returns:
            ë³‘í•©ëœ íšŒì˜ ìŒì„± ì¸ì‹ ê²°ê³¼
        """
        try:
            self.log_info(f"íšŒì˜ ì²­í¬ë³„ ìŒì„± ì¸ì‹ ì‹œì‘: {len(chunk_paths)}ê°œ ì²­í¬")
            
            # ì²­í¬ë³„ ìŒì„± ì¸ì‹
            chunk_results = self.transcribe_chunks(chunk_paths, language)
            
            # ê²°ê³¼ ë³‘í•©
            merged_result = self.merge_transcription_results(chunk_results)
            
            # íšŒì˜ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            merged_result.update({
                "meeting_id": self.meeting_id,
                "meeting_type": "chunked_meeting",
                "transcription_timestamp": datetime.now().isoformat(),
                "chunk_results": chunk_results
            })
            
            # í†µê³„ ì •ë³´ ì¶”ê°€
            stats = self.get_transcription_stats(merged_result)
            merged_result["stats"] = stats
            
            self.log_info(f"íšŒì˜ ì²­í¬ë³„ ìŒì„± ì¸ì‹ ì™„ë£Œ: {stats['word_count']}ë‹¨ì–´, {stats['duration_seconds']:.1f}ì´ˆ")
            return merged_result
            
        except Exception as e:
            self.log_error(f"íšŒì˜ ì²­í¬ë³„ ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}")
            raise
